{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ea8fba-ed8c-4a5e-8b6b-6428ff119b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8379c79-907e-4e30-9941-691e4c687178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "def export_labels_to_model(model_name: str, model) -> None:\n",
    "    \"\"\"\n",
    "    Reads from a model configuration to export the labels of the class target to a file in the model's assets folder.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model. This is used to create a directory for the model.\n",
    "      model: The model to export.\n",
    "    \"\"\"\n",
    "    labels = model.config.label2id\n",
    "    labels = sorted(labels, key=labels.get)\n",
    "\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    with open(f'{model_assets_path}/labels.txt', 'w') as f:\n",
    "        f.write('\\n'.join(labels))\n",
    "\n",
    "def save_model_from_hub(model_name: str) -> None:\n",
    "    \"\"\"\n",
    "    We load the model and tokenizer from the HuggingFace hub, save them to the `models` directory, and then export\n",
    "    the labels of the model to the directory that contains all the assets.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to save.\n",
    "    \"\"\"\n",
    "\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model.save_pretrained(f'models/{model_name}', from_tf=True, save_format='tf', saved_model=True)\n",
    "    tokenizer.save_pretrained(f'models/{model_name}_tokenizer', from_tf=True, save_format='tf')\n",
    "    export_labels_to_model(model_name, model)\n",
    "\n",
    "    print(f\"Model {model_name} saved.\")\n",
    "\n",
    "def copy_tokenizer_vocab_to_model(model_name):\n",
    "    \"\"\"\n",
    "    We copy the tokenizer's vocabulary to the model's directory, so that we can use the model for\n",
    "    predictions.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model you want to use.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer_vocab_path = f'models/{model_name}_tokenizer/vocab.txt'\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    shutil.copyfile(tokenizer_vocab_path, f'{model_assets_path}/vocab.txt')\n",
    "    \n",
    "\n",
    "def prepare_model_from_hub(model_name: str, model_dir:str) -> None:\n",
    "    \"\"\"\n",
    "    If the model directory doesn't exist, download the model from the HuggingFace Hub, and copy the tokenizer\n",
    "    vocab to the model directory so that the format can be digested by Spark NLP.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to use.\n",
    "      model_dir (str): The directory where the model will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "    if not Path(model_path).is_dir():\n",
    "        save_model_from_hub(model_name)\n",
    "        copy_tokenizer_vocab_to_model(model_name)\n",
    "\n",
    "def get_label_metadata(dataset):\n",
    "  \"\"\"\n",
    "  It takes a dataset and returns a list of labels, a dictionary mapping label ids to labels, and a\n",
    "  dictionary mapping labels to label ids\n",
    "  \n",
    "  Args:\n",
    "    dataset: the dataset object\n",
    "  \"\"\"\n",
    "  labels = [label for label in dataset['train'].features.keys() if label not in ['text', 'label_descriptions']]\n",
    "  id2label = dict(enumerate(labels))\n",
    "  label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "  return labels, id2label, label2id\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  \"\"\"\n",
    "  It takes in the predictions and labels from the model, and returns a dictionary of metrics.\n",
    "  Logits are converted into probabilities following a sigmoid function; then, the predictions are\n",
    "  converted into binary values by comparing the probabilities to a threshold.\n",
    "  \n",
    "  Args:\n",
    "    eval_pred: a tuple of (predictions, labels)\n",
    "  \n",
    "  Returns:\n",
    "    A dictionary with the accuracy, f1_micro and f1_macro\n",
    "  \"\"\"\n",
    "  sigmoid_threshold = 0.3\n",
    "  #print(eval_pred)  \n",
    "  predictions, labels = eval_pred\n",
    "  #print( predictions, labels)  \n",
    "  accuracy = accuracy_thresh(predictions, labels, sigmoid_threshold)\n",
    "  f1_micro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"micro\")\n",
    "  f1_macro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"macro\")\n",
    "  #confusion_matrix = sklearn.metrics.confusion_matrix(labels.flatten(), (predictions > 0.5).flatten().astype(int))\n",
    "  #print(confusion_matrix)  \n",
    "  return {\n",
    "      \"accuracy_thresh\": accuracy,\n",
    "      \"f1_micro\": f1_micro,\n",
    "      \"f1_macro\": f1_macro,\n",
    "      \"eval_f1\": f1_micro\n",
    "  }\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh): \n",
    "    \"\"\"\n",
    "    It takes in a predicted probability and a true label, and returns the accuracy of the prediction\n",
    "    \n",
    "    Args:\n",
    "      y_pred: the predicted values\n",
    "      y_true: the ground truth labels\n",
    "      thresh: the threshold for the prediction to be considered a positive prediction.\n",
    "    \n",
    "    Returns:\n",
    "      The mean of the accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    y_pred = torch.from_numpy(y_pred).sigmoid()\n",
    "    #print(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    #print(y_true)\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()\n",
    "\n",
    "\n",
    "def prepare_splits_for_training(dataset, subset_data):\n",
    "  \"\"\"Splits and shuffles the dataset into train and test splits.\n",
    "\n",
    "  Args:\n",
    "      dataset (DatasetDict): The dataset to split. \n",
    "      subset_data (bool, optional): Flag to use a subset of the data.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[Dataset]: One dataset object per train, test split.\n",
    "  \"\"\"\n",
    "  fraction = 0.05 if subset_data else 1\n",
    "  splits = [dataset[\"train\"], dataset[\"test\"]]\n",
    "\n",
    "  return [\n",
    "    split.shuffle(seed=42).select(range(int(len(split) * fraction)))\n",
    "    for split in splits\n",
    "  ]\n",
    "\n",
    "def convert_to_tf_dataset(dataset, data_collator, shuffle_flag, batch_size):\n",
    "  \"\"\"\n",
    "  We convert the dataset to a tf.data.Dataset object, which is a TensorFlow object that can be used\n",
    "  to train a model\n",
    "  \n",
    "  Args:\n",
    "    dataset: The dataset to convert to a tf.data.Dataset.\n",
    "    data_collator: This is a function that takes in a list of tensors and returns a single tensor.\n",
    "    shuffle_flag: Whether to shuffle the dataset or not.\n",
    "    batch_size: The number of samples per batch.\n",
    "  \n",
    "  Returns:\n",
    "    A tf.data.Dataset object\n",
    "  \"\"\"\n",
    "  return (\n",
    "      dataset.to_tf_dataset(\n",
    "          columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "          label_cols=[\"labels\"],\n",
    "          shuffle=shuffle_flag,\n",
    "          collate_fn=data_collator,\n",
    "          batch_size=batch_size\n",
    "      )\n",
    "  )\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    \"\"\"Cleans and removes special characters from the text.\"\"\"\n",
    "\n",
    "    replacements = [\n",
    "        (r\"what's\", \"what is \"),\n",
    "        (r\"won't\", \"will not \"),\n",
    "        (r\"\\'s\", \" \"),\n",
    "        (r\"\\'ve\", \" have \"),\n",
    "        (r\"can't\", \"can not \"),\n",
    "        (r\"n't\", \" not \"),\n",
    "        (r\"i'm\", \"i am \"),\n",
    "        (r\"\\'re\", \" are \"),\n",
    "        (r\"\\'d\", \" would \"),\n",
    "        (r\"\\'ll\", \" will \"),\n",
    "        (r\"\\'scuse\", \" excuse \"),\n",
    "        (r\"\\'\\n\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\"\\'\\xa0\", \" \"),\n",
    "        (r\"(@.*?)[\\s]\", \" \"),\n",
    "        (r\"&amp;\", \"&\"),\n",
    "    ]\n",
    "    \n",
    "    text = text.lower()\n",
    "    for pattern, replacement in replacements:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3131199-b09d-4d37-a563-11b413a45fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \"\"\"Tokenises the text and creates a numpy array with its assigned labels.\"\"\"\n",
    "    text = [preprocess_text(text) for text in batch[\"text\"]]\n",
    "    encoding = tokenizer(text, max_length=177, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    labels_batch = {k: batch[k] for k in batch.keys() if k in labels}\n",
    "    #print(labels_batch)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for idx, label in enumerate(labels):\n",
    "        #print(label)\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    #print(labels_matrix)\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    #print(encoding[\"labels\"])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a014669a-231a-437d-a20d-3bbc603b8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            Custom loss function calculation using BCEWithLogitsLoss, it returns the loss and the outputs if the\n",
    "            return_outputs flag is set to True\n",
    "            This function is used during training, evaluation, and prediction; specifically every time a batch is processed.\n",
    "            The default loss function is here https://github.com/huggingface/transformers/blob/820c46a707ddd033975bc3b0549eea200e64c7da/src/transformers/trainer.py#L2561\n",
    "            \n",
    "            Args:\n",
    "              model: the model we're training\n",
    "              inputs: a dictionary of input tensors\n",
    "              return_outputs: if True, the loss and the model outputs are returned. If False, only the loss is\n",
    "            returned. Defaults to False\n",
    "            \n",
    "            Returns:\n",
    "              The loss and the outputs of the model.\n",
    "            \"\"\"\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            # forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # compute custom loss\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                            labels.float().view(-1, self.model.config.num_labels))\n",
    "            return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf99e57",
   "metadata": {},
   "source": [
    "# Testing the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89cce984-10b1-4cdc-b84e-f54c0bdc79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_classifier(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfd8b0a-30a8-4a5b-9186-f7cf61f8fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='epoch'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model=instantiate_classifier(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    trainer.save_model(output_model_name)\n",
    "    if push_to_hub:\n",
    "        trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b28d70a3-165d-4268-a5ab-5a17545f4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 10:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.222329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.347979</td>\n",
       "      <td>0.936941</td>\n",
       "      <td>0.347979</td>\n",
       "      <td>0.045496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.182911</td>\n",
       "      <td>0.319846</td>\n",
       "      <td>0.942902</td>\n",
       "      <td>0.319846</td>\n",
       "      <td>0.047401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.166113</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.090466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.148894</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>0.183926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.138052</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.156130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.123628</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.961255</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.207971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.115981</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>0.291283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.110649</td>\n",
       "      <td>0.693410</td>\n",
       "      <td>0.965490</td>\n",
       "      <td>0.693410</td>\n",
       "      <td>0.306426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.110102</td>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.965020</td>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.379032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.103770</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.966118</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.394022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.445350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.741809</td>\n",
       "      <td>0.966274</td>\n",
       "      <td>0.741809</td>\n",
       "      <td>0.456037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.102586</td>\n",
       "      <td>0.748353</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.748353</td>\n",
       "      <td>0.473469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.485723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.105334</td>\n",
       "      <td>0.743523</td>\n",
       "      <td>0.965176</td>\n",
       "      <td>0.743523</td>\n",
       "      <td>0.455574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.102956</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.745501</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.745501</td>\n",
       "      <td>0.481174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.103534</td>\n",
       "      <td>0.744246</td>\n",
       "      <td>0.965804</td>\n",
       "      <td>0.744246</td>\n",
       "      <td>0.478656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory stop_reasons/checkpoint-2120 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7553191489361702, 'eval_loss': 0.10010654479265213, 'eval_accuracy_thresh': 0.9679999947547913, 'eval_f1_micro': 0.7553191489361702, 'eval_f1_macro': 0.44535013143424784, 'eval_runtime': 1.1242, 'eval_samples_per_second': 333.572, 'eval_steps_per_second': 10.674, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-6.1578274 , -4.349581  , -5.2267456 , ..., -2.925995  ,\n",
      "        -7.59398   , -7.6312084 ],\n",
      "       [-6.1778355 , -4.336791  , -5.2155905 , ..., -2.9656754 ,\n",
      "        -7.557175  , -7.6767106 ],\n",
      "       [-5.901342  , -3.7539372 , -5.0187736 , ..., -2.6876483 ,\n",
      "        -7.1717057 , -7.239819  ],\n",
      "       ...,\n",
      "       [ 1.1950762 , -2.0148554 , -5.8048916 , ..., -1.8729451 ,\n",
      "        -2.824988  , -4.97338   ],\n",
      "       [-2.3707304 , -4.3253994 , -6.287864  , ...,  1.0312095 ,\n",
      "        -5.6261773 , -4.512992  ],\n",
      "       [-1.2205863 , -4.4121037 , -5.8266373 , ...,  0.17906903,\n",
      "        -4.6545606 , -4.9390655 ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.10010654479265213, 'test_accuracy_thresh': 0.9679999947547913, 'test_f1_micro': 0.7553191489361702, 'test_f1_macro': 0.44535013143424784, 'test_eval_f1': 0.7553191489361702, 'test_runtime': 1.1174, 'test_samples_per_second': 335.597, 'test_steps_per_second': 10.739})\n"
     ]
    }
   ],
   "source": [
    "trainer=training(model_name='domenicrosati/ClinicalTrialBioBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c0b204-3970-4b2a-8ad6-fa9406c096ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7542706964520368, 'eval_loss': 0.11011417955160141, 'eval_accuracy_thresh': 0.966901957988739, 'eval_f1_micro': 0.7542706964520368, 'eval_f1_macro': 0.46486736559453723, 'eval_runtime': 0.7703, 'eval_samples_per_second': 486.802, 'eval_steps_per_second': 15.578, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be0f0bb4-e8e9-48b1-9e1e-2e74c8f51fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d4be95315f4542a17e1205068cac1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-3.9271808 , -3.1209285 , -4.3894625 , ..., -3.6100576 ,\n",
      "        -4.401446  , -4.186394  ],\n",
      "       [-2.9825072 , -3.3565352 , -5.2395205 , ...,  1.6936542 ,\n",
      "        -3.4803228 , -3.8520677 ],\n",
      "       [ 0.23840736, -3.3388488 , -2.9050484 , ..., -1.7254094 ,\n",
      "        -3.3295286 , -1.2810366 ],\n",
      "       ...,\n",
      "       [-3.8575442 , -2.9342434 , -4.6032095 , ..., -3.4704201 ,\n",
      "        -4.4367795 , -4.2635236 ],\n",
      "       [-4.0914125 ,  2.8136544 , -6.530663  , ..., -3.807361  ,\n",
      "        -4.734856  , -5.6108866 ],\n",
      "       [-3.5844002 , -2.249797  , -2.9839425 , ..., -2.3815846 ,\n",
      "         1.2088852 , -4.242043  ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32), metrics={'test_loss': 0.0621742382645607, 'test_accuracy_thresh': 0.9867501854896545, 'test_f1_micro': 0.8902501276161306, 'test_f1_macro': 0.5756649900255171, 'test_eval_f1': 0.8902501276161306, 'test_runtime': 7.2927, 'test_samples_per_second': 513.799, 'test_steps_per_second': 16.18})\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "labels, id2label, label2id = get_label_metadata(test_dataset)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset )\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6523a57f-7a14-418f-a42f-a55e2a524160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9613    0.7487    0.8418       199\n",
      "Business_Administrative     0.9630    0.9520    0.9575       792\n",
      "                Covid19     0.9892    1.0000    0.9946       183\n",
      "           Endpoint_Met     0.0000    0.0000    0.0000        51\n",
      "         Ethical_Reason     0.0000    0.0000    0.0000        17\n",
      "      Insufficient_Data     0.0000    0.0000    0.0000        39\n",
      "Insufficient_Enrollment     0.9792    0.9647    0.9719      1075\n",
      "       Interim_Analysis     0.0000    0.0000    0.0000        28\n",
      "         Invalid_Reason     0.8856    0.8360    0.8601       250\n",
      "    Logistics_Resources     0.9521    0.5947    0.7321       301\n",
      "               Negative     0.9603    0.9212    0.9404       368\n",
      "             No_Context     0.0000    0.0000    0.0000        83\n",
      "             Regulatory     0.8842    0.7500    0.8116       112\n",
      "     Safety_Sideeffects     0.9634    0.8720    0.9154       211\n",
      "           Study_Design     0.9310    0.6990    0.7985       309\n",
      "      Study_Staff_Moved     0.9935    0.9333    0.9625       165\n",
      "                Success     0.0000    0.0000    0.0000        21\n",
      "\n",
      "              micro avg     0.9604    0.8297    0.8903      4204\n",
      "              macro avg     0.6155    0.5454    0.5757      4204\n",
      "           weighted avg     0.9046    0.8297    0.8620      4204\n",
      "            samples avg     0.9183    0.8758    0.8891      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cc7cf",
   "metadata": {},
   "source": [
    "# Testing the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa7e5337-df73-4165-885f-b4c90d8ecc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel,PeftConfig\n",
    "def instantiate_classifier_finetuned(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       'domenicrosati/ClinicalTrialBioBert',\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model,model_name,is_trainable=True)\n",
    "    #merged_model=model.merge_and_unload()\n",
    "    #for param in merged_model.parameters():\n",
    "    #     param.requires_grad = True\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('domenicrosati/ClinicalTrialBioBert', do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='no'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model= instantiate_classifier_finetuned(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    # trainer.save_model(output_model_name)\n",
    "    # if push_to_hub:\n",
    "    #     trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5b13e69-e676-4a07-a3fc-ab17793df159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 06:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.210394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155732</td>\n",
       "      <td>0.530478</td>\n",
       "      <td>0.952471</td>\n",
       "      <td>0.530478</td>\n",
       "      <td>0.152572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.130636</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.958902</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.202407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114937</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.963608</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.332821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.104436</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.967216</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.420913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.467878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>0.969412</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>0.493684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.095487</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.504375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.094918</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.970039</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.524676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.774112</td>\n",
       "      <td>0.970039</td>\n",
       "      <td>0.774112</td>\n",
       "      <td>0.511452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.968314</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.503317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098878</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.534353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.534677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.101749</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.542897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.100096</td>\n",
       "      <td>0.770389</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.770389</td>\n",
       "      <td>0.551078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.105217</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.543291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.538474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.102330</td>\n",
       "      <td>0.765370</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.765370</td>\n",
       "      <td>0.540003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.103986</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.967373</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.542820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.104307</td>\n",
       "      <td>0.769614</td>\n",
       "      <td>0.967843</td>\n",
       "      <td>0.769614</td>\n",
       "      <td>0.545873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7696139476961394, 'eval_loss': 0.10430705547332764, 'eval_accuracy_thresh': 0.9678431153297424, 'eval_f1_micro': 0.7696139476961394, 'eval_f1_macro': 0.5458725394836774, 'eval_runtime': 0.8003, 'eval_samples_per_second': 468.555, 'eval_steps_per_second': 14.994, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-6.327882 , -5.5061526, -6.6775985, ..., -2.8965   , -6.376354 ,\n",
      "        -7.5506186],\n",
      "       [-6.344967 , -6.221231 , -6.6962476, ..., -4.3206105, -6.6697307,\n",
      "        -7.7399435],\n",
      "       [-6.259497 , -5.7451634, -6.751837 , ..., -4.6739883, -6.5754023,\n",
      "        -7.640315 ],\n",
      "       ...,\n",
      "       [ 3.2270386, -3.6547203, -5.0737753, ..., -5.015713 , -5.2820845,\n",
      "        -5.5807095],\n",
      "       [-4.67397  , -4.587115 , -6.628884 , ...,  3.382313 , -5.016668 ,\n",
      "        -6.397219 ],\n",
      "       [-4.1944165, -1.1102599, -5.3798323, ..., -3.7680554, -5.387648 ,\n",
      "        -5.6805696]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.10430705547332764, 'test_accuracy_thresh': 0.9678431153297424, 'test_f1_micro': 0.7696139476961394, 'test_f1_macro': 0.5458725394836774, 'test_eval_f1': 0.7696139476961394, 'test_runtime': 0.8029, 'test_samples_per_second': 467.057, 'test_steps_per_second': 14.946})\n"
     ]
    }
   ],
   "source": [
    "trainer_new=training(model_name='checkpoint-205835')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4da71dca-68c3-4b2e-bfe5-a55c01de120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9744    0.9548    0.9645       199\n",
      "Business_Administrative     0.9712    0.9811    0.9761       792\n",
      "                Covid19     0.9946    1.0000    0.9973       183\n",
      "           Endpoint_Met     0.9474    0.7059    0.8090        51\n",
      "         Ethical_Reason     1.0000    0.1176    0.2105        17\n",
      "      Insufficient_Data     1.0000    0.1795    0.3043        39\n",
      "Insufficient_Enrollment     0.9861    0.9898    0.9879      1075\n",
      "       Interim_Analysis     1.0000    0.8214    0.9020        28\n",
      "         Invalid_Reason     0.9790    0.9320    0.9549       250\n",
      "    Logistics_Resources     0.9148    0.9269    0.9208       301\n",
      "               Negative     0.9782    0.9755    0.9769       368\n",
      "             No_Context     1.0000    0.7952    0.8859        83\n",
      "             Regulatory     0.9717    0.9196    0.9450       112\n",
      "     Safety_Sideeffects     0.9857    0.9810    0.9834       211\n",
      "           Study_Design     0.9394    0.9029    0.9208       309\n",
      "      Study_Staff_Moved     1.0000    0.9636    0.9815       165\n",
      "                Success     1.0000    0.0952    0.1739        21\n",
      "\n",
      "              micro avg     0.9733    0.9441    0.9585      4204\n",
      "              macro avg     0.9790    0.7790    0.8173      4204\n",
      "           weighted avg     0.9738    0.9441    0.9524      4204\n",
      "            samples avg     0.9654    0.9564    0.9577      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer_new.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
