{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0d52f9-248b-4bea-8ce5-51d548d4e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "def export_labels_to_model(model_name: str, model) -> None:\n",
    "    \"\"\"\n",
    "    Reads from a model configuration to export the labels of the class target to a file in the model's assets folder.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model. This is used to create a directory for the model.\n",
    "      model: The model to export.\n",
    "    \"\"\"\n",
    "    labels = model.config.label2id\n",
    "    labels = sorted(labels, key=labels.get)\n",
    "\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    with open(f'{model_assets_path}/labels.txt', 'w') as f:\n",
    "        f.write('\\n'.join(labels))\n",
    "\n",
    "def save_model_from_hub(model_name: str) -> None:\n",
    "    \"\"\"\n",
    "    We load the model and tokenizer from the HuggingFace hub, save them to the `models` directory, and then export\n",
    "    the labels of the model to the directory that contains all the assets.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to save.\n",
    "    \"\"\"\n",
    "\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model.save_pretrained(f'models/{model_name}', from_tf=True, save_format='tf', saved_model=True)\n",
    "    tokenizer.save_pretrained(f'models/{model_name}_tokenizer', from_tf=True, save_format='tf')\n",
    "    export_labels_to_model(model_name, model)\n",
    "\n",
    "    print(f\"Model {model_name} saved.\")\n",
    "\n",
    "def copy_tokenizer_vocab_to_model(model_name):\n",
    "    \"\"\"\n",
    "    We copy the tokenizer's vocabulary to the model's directory, so that we can use the model for\n",
    "    predictions.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model you want to use.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer_vocab_path = f'models/{model_name}_tokenizer/vocab.txt'\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    shutil.copyfile(tokenizer_vocab_path, f'{model_assets_path}/vocab.txt')\n",
    "    \n",
    "\n",
    "def prepare_model_from_hub(model_name: str, model_dir:str) -> None:\n",
    "    \"\"\"\n",
    "    If the model directory doesn't exist, download the model from the HuggingFace Hub, and copy the tokenizer\n",
    "    vocab to the model directory so that the format can be digested by Spark NLP.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to use.\n",
    "      model_dir (str): The directory where the model will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "    if not Path(model_path).is_dir():\n",
    "        save_model_from_hub(model_name)\n",
    "        copy_tokenizer_vocab_to_model(model_name)\n",
    "\n",
    "def get_label_metadata(dataset):\n",
    "  \"\"\"\n",
    "  It takes a dataset and returns a list of labels, a dictionary mapping label ids to labels, and a\n",
    "  dictionary mapping labels to label ids\n",
    "  \n",
    "  Args:\n",
    "    dataset: the dataset object\n",
    "  \"\"\"\n",
    "  labels = [label for label in dataset['train'].features.keys() if label not in ['text', 'label_descriptions']]\n",
    "  id2label = dict(enumerate(labels))\n",
    "  label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "  return labels, id2label, label2id\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  \"\"\"\n",
    "  It takes in the predictions and labels from the model, and returns a dictionary of metrics.\n",
    "  Logits are converted into probabilities following a sigmoid function; then, the predictions are\n",
    "  converted into binary values by comparing the probabilities to a threshold.\n",
    "  \n",
    "  Args:\n",
    "    eval_pred: a tuple of (predictions, labels)\n",
    "  \n",
    "  Returns:\n",
    "    A dictionary with the accuracy, f1_micro and f1_macro\n",
    "  \"\"\"\n",
    "  sigmoid_threshold = 0.3\n",
    "  #print(eval_pred)  \n",
    "  predictions, labels = eval_pred\n",
    "  #print( predictions, labels)  \n",
    "  predictions = torch.from_numpy(predictions).sigmoid()\n",
    "  #print(y_pred)\n",
    "  labels = torch.from_numpy(labels) \n",
    "  #print( predictions, labels)    \n",
    "  accuracy = accuracy_thresh(predictions, labels, sigmoid_threshold)\n",
    "  f1_micro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"micro\")\n",
    "  f1_macro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"macro\")\n",
    "  #confusion_matrix = sklearn.metrics.confusion_matrix(labels.flatten(), (predictions > 0.5).flatten().astype(int))\n",
    "  #print(confusion_matrix)  \n",
    "  return {\n",
    "      \"accuracy_thresh\": accuracy,\n",
    "      \"f1_micro\": f1_micro,\n",
    "      \"f1_macro\": f1_macro,\n",
    "      \"eval_f1\": f1_micro\n",
    "  }\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh): \n",
    "    \"\"\"\n",
    "    It takes in a predicted probability and a true label, and returns the accuracy of the prediction\n",
    "    \n",
    "    Args:\n",
    "      y_pred: the predicted values\n",
    "      y_true: the ground truth labels\n",
    "      thresh: the threshold for the prediction to be considered a positive prediction.\n",
    "    \n",
    "    Returns:\n",
    "      The mean of the accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    #y_pred = torch.from_numpy(y_pred).sigmoid()\n",
    "    #print(y_pred)\n",
    "    #y_true = torch.from_numpy(y_true)\n",
    "    #print(y_true)\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()\n",
    "\n",
    "\n",
    "def prepare_splits_for_training(dataset, subset_data):\n",
    "  \"\"\"Splits and shuffles the dataset into train and test splits.\n",
    "\n",
    "  Args:\n",
    "      dataset (DatasetDict): The dataset to split. \n",
    "      subset_data (bool, optional): Flag to use a subset of the data.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[Dataset]: One dataset object per train, test split.\n",
    "  \"\"\"\n",
    "  fraction = 0.05 if subset_data else 1\n",
    "  splits = [dataset[\"train\"], dataset[\"test\"]]\n",
    "\n",
    "  return [\n",
    "    split.shuffle(seed=42).select(range(int(len(split) * fraction)))\n",
    "    for split in splits\n",
    "  ]\n",
    "\n",
    "def convert_to_tf_dataset(dataset, data_collator, shuffle_flag, batch_size):\n",
    "  \"\"\"\n",
    "  We convert the dataset to a tf.data.Dataset object, which is a TensorFlow object that can be used\n",
    "  to train a model\n",
    "  \n",
    "  Args:\n",
    "    dataset: The dataset to convert to a tf.data.Dataset.\n",
    "    data_collator: This is a function that takes in a list of tensors and returns a single tensor.\n",
    "    shuffle_flag: Whether to shuffle the dataset or not.\n",
    "    batch_size: The number of samples per batch.\n",
    "  \n",
    "  Returns:\n",
    "    A tf.data.Dataset object\n",
    "  \"\"\"\n",
    "  return (\n",
    "      dataset.to_tf_dataset(\n",
    "          columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "          label_cols=[\"labels\"],\n",
    "          shuffle=shuffle_flag,\n",
    "          collate_fn=data_collator,\n",
    "          batch_size=batch_size\n",
    "      )\n",
    "  )\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    \"\"\"Cleans and removes special characters from the text.\"\"\"\n",
    "\n",
    "    replacements = [\n",
    "        (r\"what's\", \"what is \"),\n",
    "        (r\"won't\", \"will not \"),\n",
    "        (r\"\\'s\", \" \"),\n",
    "        (r\"\\'ve\", \" have \"),\n",
    "        (r\"can't\", \"can not \"),\n",
    "        (r\"n't\", \" not \"),\n",
    "        (r\"i'm\", \"i am \"),\n",
    "        (r\"\\'re\", \" are \"),\n",
    "        (r\"\\'d\", \" would \"),\n",
    "        (r\"\\'ll\", \" will \"),\n",
    "        (r\"\\'scuse\", \" excuse \"),\n",
    "        (r\"\\'\\n\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\"\\'\\xa0\", \" \"),\n",
    "        (r\"(@.*?)[\\s]\", \" \"),\n",
    "        (r\"&amp;\", \"&\"),\n",
    "    ]\n",
    "    \n",
    "    text = text.lower()\n",
    "    for pattern, replacement in replacements:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328a795d-c9d8-473e-be7f-397ba2f7fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726c9c8f-4e59-4e16-8de1-4806c78deada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \"\"\"Tokenises the text and creates a numpy array with its assigned labels.\"\"\"\n",
    "    text = [preprocess_text(text) for text in batch[\"text\"]]\n",
    "    encoding = tokenizer(text, max_length=177, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    labels_batch = {k: batch[k] for k in batch.keys() if k in labels}\n",
    "    #print(labels_batch)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for idx, label in enumerate(labels):\n",
    "        #print(label)\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    #print(labels_matrix)\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    #print(encoding[\"labels\"])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a139bf-f3fc-4512-84ce-d3d10e56dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            Custom loss function calculation using BCEWithLogitsLoss, it returns the loss and the outputs if the\n",
    "            return_outputs flag is set to True\n",
    "            This function is used during training, evaluation, and prediction; specifically every time a batch is processed.\n",
    "            The default loss function is here https://github.com/huggingface/transformers/blob/820c46a707ddd033975bc3b0549eea200e64c7da/src/transformers/trainer.py#L2561\n",
    "            \n",
    "            Args:\n",
    "              model: the model we're training\n",
    "              inputs: a dictionary of input tensors\n",
    "              return_outputs: if True, the loss and the model outputs are returned. If False, only the loss is\n",
    "            returned. Defaults to False\n",
    "            \n",
    "            Returns:\n",
    "              The loss and the outputs of the model.\n",
    "            \"\"\"\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            # forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # compute custom loss\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                            labels.float().view(-1, self.model.config.num_labels))\n",
    "            return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "573e4de6-541e-4fdd-bfb3-f54ab016a0af",
   "metadata": {},
   "source": [
    "Non-Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fedb65-e589-4f63-b749-3909757c4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_classifier(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa321abc-699c-4894-92cb-a4373a6c76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='epoch'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model=instantiate_classifier(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    trainer.save_model(output_model_name)\n",
    "    if push_to_hub:\n",
    "        trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703cb6de-ff2c-4a89-ade0-590f465d54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 07:45, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198114</td>\n",
       "      <td>0.429043</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.429043</td>\n",
       "      <td>0.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174140</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.956078</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.178022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.148752</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.960157</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.286526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.130123</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.961569</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.367020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.117275</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.966902</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.446650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.118048</td>\n",
       "      <td>0.719320</td>\n",
       "      <td>0.963765</td>\n",
       "      <td>0.719320</td>\n",
       "      <td>0.433648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.744298</td>\n",
       "      <td>0.966588</td>\n",
       "      <td>0.744298</td>\n",
       "      <td>0.483299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.101032</td>\n",
       "      <td>0.768862</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.768862</td>\n",
       "      <td>0.512534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.100891</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.523386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.097519</td>\n",
       "      <td>0.769591</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.769591</td>\n",
       "      <td>0.521360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.098978</td>\n",
       "      <td>0.769417</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.769417</td>\n",
       "      <td>0.516926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.094638</td>\n",
       "      <td>0.775414</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.775414</td>\n",
       "      <td>0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.097286</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>0.524756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.098278</td>\n",
       "      <td>0.770883</td>\n",
       "      <td>0.969882</td>\n",
       "      <td>0.770883</td>\n",
       "      <td>0.520610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.098861</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.515590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.098784</td>\n",
       "      <td>0.761792</td>\n",
       "      <td>0.968314</td>\n",
       "      <td>0.761792</td>\n",
       "      <td>0.515855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.099357</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.967843</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.508168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.099553</td>\n",
       "      <td>0.757647</td>\n",
       "      <td>0.967686</td>\n",
       "      <td>0.757647</td>\n",
       "      <td>0.511815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7759433962264151, 'eval_loss': 0.09728629887104034, 'eval_accuracy_thresh': 0.9701960682868958, 'eval_f1_micro': 0.7759433962264151, 'eval_f1_macro': 0.5247557221952606, 'eval_runtime': 0.7866, 'eval_samples_per_second': 476.753, 'eval_steps_per_second': 15.256, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-5.179295 , -3.4378521, -7.831208 , ..., -3.1311064, -8.554558 ,\n",
      "        -5.128829 ],\n",
      "       [-5.3846283, -4.1228495, -8.102286 , ..., -3.4741073, -8.864204 ,\n",
      "        -5.245756 ],\n",
      "       [-5.380349 , -3.9970558, -8.088544 , ..., -3.4552574, -8.8096485,\n",
      "        -5.211628 ],\n",
      "       ...,\n",
      "       [ 1.6839526, -4.702727 , -3.568052 , ..., -2.6990564, -4.2404666,\n",
      "        -4.796734 ],\n",
      "       [-3.069668 , -4.4003973, -4.170887 , ...,  2.36044  , -6.1254663,\n",
      "        -5.298255 ],\n",
      "       [-3.1181903, -2.4374201, -5.98372  , ..., -2.8834758, -3.3140206,\n",
      "        -2.538319 ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.09728629887104034, 'test_accuracy_thresh': 0.9701960682868958, 'test_f1_micro': 0.7759433962264151, 'test_f1_macro': 0.5247557221952606, 'test_eval_f1': 0.7759433962264151, 'test_runtime': 0.8304, 'test_samples_per_second': 451.572, 'test_steps_per_second': 14.45})\n"
     ]
    }
   ],
   "source": [
    "trainer=training(model_name='domenicrosati/ClinicalTrialBioBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227a3f8b-fe2f-45d6-a5cb-2939c9fd3e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9455    0.9598    0.9526       199\n",
      "Business_Administrative     0.9570    0.9545    0.9558       792\n",
      "                Covid19     1.0000    1.0000    1.0000       183\n",
      "           Endpoint_Met     0.7500    0.1176    0.2034        51\n",
      "         Ethical_Reason     0.0000    0.0000    0.0000        17\n",
      "      Insufficient_Data     0.0000    0.0000    0.0000        39\n",
      "Insufficient_Enrollment     0.9832    0.9814    0.9823      1075\n",
      "       Interim_Analysis     0.0000    0.0000    0.0000        28\n",
      "         Invalid_Reason     0.9051    0.9160    0.9105       250\n",
      "    Logistics_Resources     0.8407    0.8239    0.8322       301\n",
      "               Negative     0.9672    0.9620    0.9646       368\n",
      "             No_Context     0.9661    0.6867    0.8028        83\n",
      "             Regulatory     0.8583    0.9196    0.8879       112\n",
      "     Safety_Sideeffects     0.9761    0.9668    0.9714       211\n",
      "           Study_Design     0.8776    0.8123    0.8437       309\n",
      "      Study_Staff_Moved     0.9186    0.9576    0.9377       165\n",
      "                Success     1.0000    0.0476    0.0909        21\n",
      "\n",
      "              micro avg     0.9450    0.9029    0.9235      4204\n",
      "              macro avg     0.7615    0.6533    0.6668      4204\n",
      "           weighted avg     0.9243    0.9029    0.9080      4204\n",
      "            samples avg     0.9448    0.9294    0.9310      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "true_labels = np.array(tokenized_test_dataset[\"labels\"]).astype(bool)\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "predictions = torch.from_numpy(predictions).sigmoid()\n",
    "true_labels = torch.from_numpy(true_labels) \n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d899adb1",
   "metadata": {},
   "source": [
    "Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9aa20d8-9a12-4a56-bacf-79d0c5c77843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel,PeftConfig\n",
    "def instantiate_classifier_finetuned(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       'domenicrosati/ClinicalTrialBioBert',\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model,model_name,is_trainable=True)\n",
    "    #model=model.merge_and_unload()\n",
    "    for param in model.parameters():\n",
    "          param.requires_grad = True\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('domenicrosati/ClinicalTrialBioBert', do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='no'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model= instantiate_classifier_finetuned(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    # trainer.save_model(output_model_name)\n",
    "    # if push_to_hub:\n",
    "    #     trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde87adf-1a6b-4863-a60b-2756c60d57b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 07:27, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208425</td>\n",
       "      <td>0.246206</td>\n",
       "      <td>0.929882</td>\n",
       "      <td>0.246206</td>\n",
       "      <td>0.030672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.162480</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.948392</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.178522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.633508</td>\n",
       "      <td>0.956078</td>\n",
       "      <td>0.633508</td>\n",
       "      <td>0.277524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106369</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.481108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.094497</td>\n",
       "      <td>0.771635</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.771635</td>\n",
       "      <td>0.510942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.093101</td>\n",
       "      <td>0.771290</td>\n",
       "      <td>0.970510</td>\n",
       "      <td>0.771290</td>\n",
       "      <td>0.510986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.971765</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.547823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.088180</td>\n",
       "      <td>0.778973</td>\n",
       "      <td>0.970980</td>\n",
       "      <td>0.778973</td>\n",
       "      <td>0.543498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.094823</td>\n",
       "      <td>0.761457</td>\n",
       "      <td>0.968157</td>\n",
       "      <td>0.761457</td>\n",
       "      <td>0.553294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.528892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.094606</td>\n",
       "      <td>0.773893</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.773893</td>\n",
       "      <td>0.566708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.094485</td>\n",
       "      <td>0.789779</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>0.789779</td>\n",
       "      <td>0.589900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.093279</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.566549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.768166</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.768166</td>\n",
       "      <td>0.575134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.093141</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.575458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.094086</td>\n",
       "      <td>0.778555</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.778555</td>\n",
       "      <td>0.579423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.094601</td>\n",
       "      <td>0.789598</td>\n",
       "      <td>0.972078</td>\n",
       "      <td>0.789598</td>\n",
       "      <td>0.586620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.097850</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.970980</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.579479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>0.782710</td>\n",
       "      <td>0.970824</td>\n",
       "      <td>0.782710</td>\n",
       "      <td>0.579474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.581415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7859649122807018, 'eval_loss': 0.09819208830595016, 'eval_accuracy_thresh': 0.971294105052948, 'eval_f1_micro': 0.7859649122807018, 'eval_f1_macro': 0.5814147499802844, 'eval_runtime': 0.7785, 'eval_samples_per_second': 481.673, 'eval_steps_per_second': 15.414, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-5.5445943 , -5.9934154 , -7.046057  , ..., -2.5061266 ,\n",
      "        -6.350135  , -7.3434014 ],\n",
      "       [-6.1627617 , -6.4783897 , -7.0276675 , ..., -4.198851  ,\n",
      "        -6.9666696 , -7.855377  ],\n",
      "       [-6.5516067 , -5.7640424 , -6.816563  , ..., -4.1927013 ,\n",
      "        -6.7160454 , -7.5685945 ],\n",
      "       ...,\n",
      "       [ 3.4823356 , -2.1001017 , -5.1224527 , ..., -5.0763335 ,\n",
      "        -4.8721075 , -5.421452  ],\n",
      "       [-4.9112577 , -5.0351677 , -6.372191  , ...,  3.4419606 ,\n",
      "        -5.538386  , -6.7094398 ],\n",
      "       [-5.9622145 , -0.81831294, -6.0952506 , ..., -1.5838529 ,\n",
      "        -4.2679796 , -5.8804593 ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.09819208830595016, 'test_accuracy_thresh': 0.971294105052948, 'test_f1_micro': 0.7859649122807018, 'test_f1_macro': 0.5814147499802844, 'test_eval_f1': 0.7859649122807018, 'test_runtime': 0.799, 'test_samples_per_second': 469.334, 'test_steps_per_second': 15.019})\n"
     ]
    }
   ],
   "source": [
    "trainer_new=training(model_name='checkpoint-205835')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d0259d-618b-43fd-8ffe-27963354a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9747    0.9698    0.9723       199\n",
      "Business_Administrative     0.9666    0.9861    0.9762       792\n",
      "                Covid19     0.9946    1.0000    0.9973       183\n",
      "           Endpoint_Met     0.6923    0.8824    0.7759        51\n",
      "         Ethical_Reason     0.9333    0.8235    0.8750        17\n",
      "      Insufficient_Data     0.9130    0.5385    0.6774        39\n",
      "Insufficient_Enrollment     0.9808    0.9953    0.9880      1075\n",
      "       Interim_Analysis     0.9286    0.9286    0.9286        28\n",
      "         Invalid_Reason     0.9636    0.9520    0.9577       250\n",
      "    Logistics_Resources     0.8743    0.9701    0.9197       301\n",
      "               Negative     0.9758    0.9864    0.9811       368\n",
      "             No_Context     0.9359    0.8795    0.9068        83\n",
      "             Regulatory     0.9640    0.9554    0.9596       112\n",
      "     Safety_Sideeffects     0.9858    0.9905    0.9882       211\n",
      "           Study_Design     0.9161    0.8835    0.8995       309\n",
      "      Study_Staff_Moved     0.9939    0.9939    0.9939       165\n",
      "                Success     0.6400    0.7619    0.6957        21\n",
      "\n",
      "              micro avg     0.9563    0.9676    0.9619      4204\n",
      "              macro avg     0.9196    0.9116    0.9113      4204\n",
      "           weighted avg     0.9576    0.9676    0.9618      4204\n",
      "            samples avg     0.9702    0.9761    0.9693      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer_new.predict(tokenized_test_dataset).predictions\n",
    "true_labels = np.array(tokenized_test_dataset[\"labels\"]).astype(bool)\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "predictions = torch.from_numpy(predictions).sigmoid()\n",
    "true_labels = torch.from_numpy(true_labels) \n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
