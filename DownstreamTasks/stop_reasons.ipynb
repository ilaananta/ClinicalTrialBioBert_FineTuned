{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8379c79-907e-4e30-9941-691e4c687178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "def export_labels_to_model(model_name: str, model) -> None:\n",
    "    \"\"\"\n",
    "    Reads from a model configuration to export the labels of the class target to a file in the model's assets folder.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model. This is used to create a directory for the model.\n",
    "      model: The model to export.\n",
    "    \"\"\"\n",
    "    labels = model.config.label2id\n",
    "    labels = sorted(labels, key=labels.get)\n",
    "\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    with open(f'{model_assets_path}/labels.txt', 'w') as f:\n",
    "        f.write('\\n'.join(labels))\n",
    "\n",
    "def save_model_from_hub(model_name: str) -> None:\n",
    "    \"\"\"\n",
    "    We load the model and tokenizer from the HuggingFace hub, save them to the `models` directory, and then export\n",
    "    the labels of the model to the directory that contains all the assets.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to save.\n",
    "    \"\"\"\n",
    "\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model.save_pretrained(f'models/{model_name}', from_tf=True, save_format='tf', saved_model=True)\n",
    "    tokenizer.save_pretrained(f'models/{model_name}_tokenizer', from_tf=True, save_format='tf')\n",
    "    export_labels_to_model(model_name, model)\n",
    "\n",
    "    print(f\"Model {model_name} saved.\")\n",
    "\n",
    "def copy_tokenizer_vocab_to_model(model_name):\n",
    "    \"\"\"\n",
    "    We copy the tokenizer's vocabulary to the model's directory, so that we can use the model for\n",
    "    predictions.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model you want to use.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer_vocab_path = f'models/{model_name}_tokenizer/vocab.txt'\n",
    "    model_assets_path = f'models/{model_name}/saved_model/1/assets'\n",
    "\n",
    "    shutil.copyfile(tokenizer_vocab_path, f'{model_assets_path}/vocab.txt')\n",
    "    \n",
    "\n",
    "def prepare_model_from_hub(model_name: str, model_dir:str) -> None:\n",
    "    \"\"\"\n",
    "    If the model directory doesn't exist, download the model from the HuggingFace Hub, and copy the tokenizer\n",
    "    vocab to the model directory so that the format can be digested by Spark NLP.\n",
    "    \n",
    "    Args:\n",
    "      model_name (str): The name of the model you want to use.\n",
    "      model_dir (str): The directory where the model will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    model_path = f'{model_dir}/{model_name}'\n",
    "\n",
    "    if not Path(model_path).is_dir():\n",
    "        save_model_from_hub(model_name)\n",
    "        copy_tokenizer_vocab_to_model(model_name)\n",
    "\n",
    "def get_label_metadata(dataset):\n",
    "  \"\"\"\n",
    "  It takes a dataset and returns a list of labels, a dictionary mapping label ids to labels, and a\n",
    "  dictionary mapping labels to label ids\n",
    "  \n",
    "  Args:\n",
    "    dataset: the dataset object\n",
    "  \"\"\"\n",
    "  labels = [label for label in dataset['train'].features.keys() if label not in ['text', 'label_descriptions']]\n",
    "  id2label = dict(enumerate(labels))\n",
    "  label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "  return labels, id2label, label2id\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  \"\"\"\n",
    "  It takes in the predictions and labels from the model, and returns a dictionary of metrics.\n",
    "  Logits are converted into probabilities following a sigmoid function; then, the predictions are\n",
    "  converted into binary values by comparing the probabilities to a threshold.\n",
    "  \n",
    "  Args:\n",
    "    eval_pred: a tuple of (predictions, labels)\n",
    "  \n",
    "  Returns:\n",
    "    A dictionary with the accuracy, f1_micro and f1_macro\n",
    "  \"\"\"\n",
    "  sigmoid_threshold = 0.3\n",
    "  #print(eval_pred)  \n",
    "  predictions, labels = eval_pred\n",
    "  #print( predictions, labels)  \n",
    "  accuracy = accuracy_thresh(predictions, labels, sigmoid_threshold)\n",
    "  f1_micro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"micro\")\n",
    "  f1_macro = sklearn.metrics.f1_score(labels, (predictions > sigmoid_threshold), average=\"macro\")\n",
    "  #confusion_matrix = sklearn.metrics.confusion_matrix(labels.flatten(), (predictions > 0.5).flatten().astype(int))\n",
    "  #print(confusion_matrix)  \n",
    "  return {\n",
    "      \"accuracy_thresh\": accuracy,\n",
    "      \"f1_micro\": f1_micro,\n",
    "      \"f1_macro\": f1_macro,\n",
    "      \"eval_f1\": f1_micro\n",
    "  }\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh): \n",
    "    \"\"\"\n",
    "    It takes in a predicted probability and a true label, and returns the accuracy of the prediction\n",
    "    \n",
    "    Args:\n",
    "      y_pred: the predicted values\n",
    "      y_true: the ground truth labels\n",
    "      thresh: the threshold for the prediction to be considered a positive prediction.\n",
    "    \n",
    "    Returns:\n",
    "      The mean of the accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    y_pred = torch.from_numpy(y_pred).sigmoid()\n",
    "    #print(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    #print(y_true)\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()\n",
    "\n",
    "\n",
    "def prepare_splits_for_training(dataset, subset_data):\n",
    "  \"\"\"Splits and shuffles the dataset into train and test splits.\n",
    "\n",
    "  Args:\n",
    "      dataset (DatasetDict): The dataset to split. \n",
    "      subset_data (bool, optional): Flag to use a subset of the data.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[Dataset]: One dataset object per train, test split.\n",
    "  \"\"\"\n",
    "  fraction = 0.05 if subset_data else 1\n",
    "  splits = [dataset[\"train\"], dataset[\"test\"]]\n",
    "\n",
    "  return [\n",
    "    split.shuffle(seed=42).select(range(int(len(split) * fraction)))\n",
    "    for split in splits\n",
    "  ]\n",
    "\n",
    "def convert_to_tf_dataset(dataset, data_collator, shuffle_flag, batch_size):\n",
    "  \"\"\"\n",
    "  We convert the dataset to a tf.data.Dataset object, which is a TensorFlow object that can be used\n",
    "  to train a model\n",
    "  \n",
    "  Args:\n",
    "    dataset: The dataset to convert to a tf.data.Dataset.\n",
    "    data_collator: This is a function that takes in a list of tensors and returns a single tensor.\n",
    "    shuffle_flag: Whether to shuffle the dataset or not.\n",
    "    batch_size: The number of samples per batch.\n",
    "  \n",
    "  Returns:\n",
    "    A tf.data.Dataset object\n",
    "  \"\"\"\n",
    "  return (\n",
    "      dataset.to_tf_dataset(\n",
    "          columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "          label_cols=[\"labels\"],\n",
    "          shuffle=shuffle_flag,\n",
    "          collate_fn=data_collator,\n",
    "          batch_size=batch_size\n",
    "      )\n",
    "  )\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    \"\"\"Cleans and removes special characters from the text.\"\"\"\n",
    "\n",
    "    replacements = [\n",
    "        (r\"what's\", \"what is \"),\n",
    "        (r\"won't\", \"will not \"),\n",
    "        (r\"\\'s\", \" \"),\n",
    "        (r\"\\'ve\", \" have \"),\n",
    "        (r\"can't\", \"can not \"),\n",
    "        (r\"n't\", \" not \"),\n",
    "        (r\"i'm\", \"i am \"),\n",
    "        (r\"\\'re\", \" are \"),\n",
    "        (r\"\\'d\", \" would \"),\n",
    "        (r\"\\'ll\", \" will \"),\n",
    "        (r\"\\'scuse\", \" excuse \"),\n",
    "        (r\"\\'\\n\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\"\\'\\xa0\", \" \"),\n",
    "        (r\"(@.*?)[\\s]\", \" \"),\n",
    "        (r\"&amp;\", \"&\"),\n",
    "    ]\n",
    "    \n",
    "    text = text.lower()\n",
    "    for pattern, replacement in replacements:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ea8fba-ed8c-4a5e-8b6b-6428ff119b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3131199-b09d-4d37-a563-11b413a45fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \"\"\"Tokenises the text and creates a numpy array with its assigned labels.\"\"\"\n",
    "    text = [preprocess_text(text) for text in batch[\"text\"]]\n",
    "    encoding = tokenizer(text, max_length=177, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    labels_batch = {k: batch[k] for k in batch.keys() if k in labels}\n",
    "    #print(labels_batch)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for idx, label in enumerate(labels):\n",
    "        #print(label)\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    #print(labels_matrix)\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    #print(encoding[\"labels\"])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a014669a-231a-437d-a20d-3bbc603b8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            Custom loss function calculation using BCEWithLogitsLoss, it returns the loss and the outputs if the\n",
    "            return_outputs flag is set to True\n",
    "            This function is used during training, evaluation, and prediction; specifically every time a batch is processed.\n",
    "            The default loss function is here https://github.com/huggingface/transformers/blob/820c46a707ddd033975bc3b0549eea200e64c7da/src/transformers/trainer.py#L2561\n",
    "            \n",
    "            Args:\n",
    "              model: the model we're training\n",
    "              inputs: a dictionary of input tensors\n",
    "              return_outputs: if True, the loss and the model outputs are returned. If False, only the loss is\n",
    "            returned. Defaults to False\n",
    "            \n",
    "            Returns:\n",
    "              The loss and the outputs of the model.\n",
    "            \"\"\"\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            # forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # compute custom loss\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                            labels.float().view(-1, self.model.config.num_labels))\n",
    "            return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89cce984-10b1-4cdc-b84e-f54c0bdc79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_classifier(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6bfd8b0a-30a8-4a5b-9186-f7cf61f8fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='epoch'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model=instantiate_classifier(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    trainer.save_model(output_model_name)\n",
    "    if push_to_hub:\n",
    "        trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddaa26b0-a2cb-4a29-aaf2-47c82ce6bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 09:29, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250875</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[5955    0]\n",
       " [ 420    0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214140</td>\n",
       "      <td>0.942275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[5955    0]\n",
       " [ 420    0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189374</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.367424</td>\n",
       "      <td>0.053078</td>\n",
       "      <td>[[5951    4]\n",
       " [ 329   91]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.158545</td>\n",
       "      <td>0.958274</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>[[5940   15]\n",
       " [ 328   92]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.134796</td>\n",
       "      <td>0.961412</td>\n",
       "      <td>0.597809</td>\n",
       "      <td>0.211907</td>\n",
       "      <td>[[5931   24]\n",
       " [ 247  173]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.123384</td>\n",
       "      <td>0.964549</td>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.284952</td>\n",
       "      <td>[[5917   38]\n",
       " [ 201  219]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.109274</td>\n",
       "      <td>0.968784</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>0.356071</td>\n",
       "      <td>[[5927   28]\n",
       " [ 178  242]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.108504</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.742323</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>[[5911   44]\n",
       " [ 155  265]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.098634</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.765499</td>\n",
       "      <td>0.487773</td>\n",
       "      <td>[[5922   33]\n",
       " [ 144  276]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.968314</td>\n",
       "      <td>0.777349</td>\n",
       "      <td>0.516488</td>\n",
       "      <td>[[5904   51]\n",
       " [ 121  299]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.092026</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>0.790219</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>[[5911   44]\n",
       " [ 117  303]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.099580</td>\n",
       "      <td>0.969412</td>\n",
       "      <td>0.780178</td>\n",
       "      <td>0.508884</td>\n",
       "      <td>[[5897   58]\n",
       " [ 119  301]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.792405</td>\n",
       "      <td>0.518464</td>\n",
       "      <td>[[5905   50]\n",
       " [ 110  310]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.095133</td>\n",
       "      <td>0.968157</td>\n",
       "      <td>0.781407</td>\n",
       "      <td>0.519176</td>\n",
       "      <td>[[5894   61]\n",
       " [ 113  307]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.093620</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.786070</td>\n",
       "      <td>0.515483</td>\n",
       "      <td>[[5894   61]\n",
       " [ 108  312]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.099822</td>\n",
       "      <td>0.969882</td>\n",
       "      <td>0.777917</td>\n",
       "      <td>0.506112</td>\n",
       "      <td>[[5893   62]\n",
       " [ 115  305]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.095875</td>\n",
       "      <td>0.971451</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>0.525830</td>\n",
       "      <td>[[5898   57]\n",
       " [ 108  312]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>0.971137</td>\n",
       "      <td>0.798005</td>\n",
       "      <td>0.527462</td>\n",
       "      <td>[[5896   59]\n",
       " [ 105  315]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.787578</td>\n",
       "      <td>0.518592</td>\n",
       "      <td>[[5892   63]\n",
       " [ 105  315]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.097754</td>\n",
       "      <td>0.971922</td>\n",
       "      <td>0.801480</td>\n",
       "      <td>0.548445</td>\n",
       "      <td>[[5893   62]\n",
       " [ 102  318]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.100903</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.788628</td>\n",
       "      <td>0.526209</td>\n",
       "      <td>[[5892   63]\n",
       " [ 104  316]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.787805</td>\n",
       "      <td>0.523543</td>\n",
       "      <td>[[5886   69]\n",
       " [  99  321]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.102496</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>0.793532</td>\n",
       "      <td>0.537515</td>\n",
       "      <td>[[5898   57]\n",
       " [ 105  315]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.102989</td>\n",
       "      <td>0.970510</td>\n",
       "      <td>0.788104</td>\n",
       "      <td>0.521861</td>\n",
       "      <td>[[5892   63]\n",
       " [ 105  315]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.102214</td>\n",
       "      <td>0.971137</td>\n",
       "      <td>0.797048</td>\n",
       "      <td>0.537783</td>\n",
       "      <td>[[5894   61]\n",
       " [ 101  319]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>0.971765</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>[[5889   66]\n",
       " [ 100  320]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.103686</td>\n",
       "      <td>0.971451</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.529607</td>\n",
       "      <td>[[5888   67]\n",
       " [ 103  317]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.104988</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.549594</td>\n",
       "      <td>[[5890   65]\n",
       " [ 104  316]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.104819</td>\n",
       "      <td>0.971451</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.549827</td>\n",
       "      <td>[[5891   64]\n",
       " [ 102  318]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.104631</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.792638</td>\n",
       "      <td>0.555006</td>\n",
       "      <td>[[5889   66]\n",
       " [ 103  317]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[[5955    0]\n",
      " [ 420    0]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5955    0]\n",
      " [ 420    0]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5951    4]\n",
      " [ 329   91]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5940   15]\n",
      " [ 328   92]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5931   24]\n",
      " [ 247  173]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5917   38]\n",
      " [ 201  219]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5927   28]\n",
      " [ 178  242]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5911   44]\n",
      " [ 155  265]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5922   33]\n",
      " [ 144  276]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5904   51]\n",
      " [ 121  299]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5911   44]\n",
      " [ 117  303]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5897   58]\n",
      " [ 119  301]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5905   50]\n",
      " [ 110  310]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5894   61]\n",
      " [ 113  307]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5894   61]\n",
      " [ 108  312]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5893   62]\n",
      " [ 115  305]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5898   57]\n",
      " [ 108  312]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5896   59]\n",
      " [ 105  315]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5892   63]\n",
      " [ 105  315]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5893   62]\n",
      " [ 102  318]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5892   63]\n",
      " [ 104  316]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5886   69]\n",
      " [  99  321]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5898   57]\n",
      " [ 105  315]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5892   63]\n",
      " [ 105  315]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5894   61]\n",
      " [ 101  319]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5889   66]\n",
      " [ 100  320]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5888   67]\n",
      " [ 103  317]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5890   65]\n",
      " [ 104  316]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5891   64]\n",
      " [ 102  318]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[5889   66]\n",
      " [ 103  317]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[[5889   66]\n",
      " [ 103  317]]\" of type <class 'numpy.ndarray'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10463082045316696, 'eval_accuracy_thresh': 0.971294105052948, 'eval_f1_micro': 0.7926380368098159, 'eval_f1_macro': 0.5550057315146922, 'eval_confusion_matrix': array([[5889,   66],\n",
      "       [ 103,  317]]), 'eval_runtime': 0.7899, 'eval_samples_per_second': 474.767, 'eval_steps_per_second': 15.193, 'epoch': 30.0}\n",
      "PredictionOutput(predictions=array([[ -6.912543  ,  -6.124542  , -10.360181  , ...,  -5.004137  ,\n",
      "         -9.682663  ,  -7.205182  ],\n",
      "       [ -7.0813637 ,  -6.039372  , -10.380959  , ...,  -5.2610016 ,\n",
      "         -9.799937  ,  -7.293277  ],\n",
      "       [ -6.9828467 ,  -6.081661  , -10.333856  , ...,  -5.2586884 ,\n",
      "         -9.760853  ,  -7.250233  ],\n",
      "       ...,\n",
      "       [  2.1383536 ,  -2.4037843 ,  -4.654168  , ...,  -3.6017041 ,\n",
      "         -5.3104    ,  -6.1360583 ],\n",
      "       [ -4.123867  ,  -6.3410163 ,  -5.092468  , ...,   3.4282088 ,\n",
      "         -7.6728168 ,  -8.573835  ],\n",
      "       [ -2.308239  ,  -0.18178812,  -6.974558  , ...,  -2.38515   ,\n",
      "         -6.4918327 ,  -3.823393  ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.10463082045316696, 'test_accuracy_thresh': 0.971294105052948, 'test_f1_micro': 0.7926380368098159, 'test_f1_macro': 0.5550057315146922, 'test_confusion_matrix': array([[5889,   66],\n",
      "       [ 103,  317]]), 'test_runtime': 0.7978, 'test_samples_per_second': 470.033, 'test_steps_per_second': 15.041})\n"
     ]
    }
   ],
   "source": [
    "model=main(model_name='domenicrosati/ClinicalTrialBioBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b28d70a3-165d-4268-a5ab-5a17545f4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 10:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.222329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.347979</td>\n",
       "      <td>0.936941</td>\n",
       "      <td>0.347979</td>\n",
       "      <td>0.045496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.182911</td>\n",
       "      <td>0.319846</td>\n",
       "      <td>0.942902</td>\n",
       "      <td>0.319846</td>\n",
       "      <td>0.047401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.166113</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.090466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.148894</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>0.183926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.138052</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.156130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.123628</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.961255</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.207971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.115981</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>0.291283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.110649</td>\n",
       "      <td>0.693410</td>\n",
       "      <td>0.965490</td>\n",
       "      <td>0.693410</td>\n",
       "      <td>0.306426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.110102</td>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.965020</td>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.379032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.103770</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.966118</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.394022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.445350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.741809</td>\n",
       "      <td>0.966274</td>\n",
       "      <td>0.741809</td>\n",
       "      <td>0.456037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.102586</td>\n",
       "      <td>0.748353</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.748353</td>\n",
       "      <td>0.473469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.485723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.105334</td>\n",
       "      <td>0.743523</td>\n",
       "      <td>0.965176</td>\n",
       "      <td>0.743523</td>\n",
       "      <td>0.455574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.102956</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.745501</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.745501</td>\n",
       "      <td>0.481174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.103534</td>\n",
       "      <td>0.744246</td>\n",
       "      <td>0.965804</td>\n",
       "      <td>0.744246</td>\n",
       "      <td>0.478656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory stop_reasons/checkpoint-2120 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7553191489361702, 'eval_loss': 0.10010654479265213, 'eval_accuracy_thresh': 0.9679999947547913, 'eval_f1_micro': 0.7553191489361702, 'eval_f1_macro': 0.44535013143424784, 'eval_runtime': 1.1242, 'eval_samples_per_second': 333.572, 'eval_steps_per_second': 10.674, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-6.1578274 , -4.349581  , -5.2267456 , ..., -2.925995  ,\n",
      "        -7.59398   , -7.6312084 ],\n",
      "       [-6.1778355 , -4.336791  , -5.2155905 , ..., -2.9656754 ,\n",
      "        -7.557175  , -7.6767106 ],\n",
      "       [-5.901342  , -3.7539372 , -5.0187736 , ..., -2.6876483 ,\n",
      "        -7.1717057 , -7.239819  ],\n",
      "       ...,\n",
      "       [ 1.1950762 , -2.0148554 , -5.8048916 , ..., -1.8729451 ,\n",
      "        -2.824988  , -4.97338   ],\n",
      "       [-2.3707304 , -4.3253994 , -6.287864  , ...,  1.0312095 ,\n",
      "        -5.6261773 , -4.512992  ],\n",
      "       [-1.2205863 , -4.4121037 , -5.8266373 , ...,  0.17906903,\n",
      "        -4.6545606 , -4.9390655 ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.10010654479265213, 'test_accuracy_thresh': 0.9679999947547913, 'test_f1_micro': 0.7553191489361702, 'test_f1_macro': 0.44535013143424784, 'test_eval_f1': 0.7553191489361702, 'test_runtime': 1.1174, 'test_samples_per_second': 335.597, 'test_steps_per_second': 10.739})\n"
     ]
    }
   ],
   "source": [
    "trainer=training(model_name='domenicrosati/ClinicalTrialBioBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c0b204-3970-4b2a-8ad6-fa9406c096ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7542706964520368, 'eval_loss': 0.11011417955160141, 'eval_accuracy_thresh': 0.966901957988739, 'eval_f1_micro': 0.7542706964520368, 'eval_f1_macro': 0.46486736559453723, 'eval_runtime': 0.7703, 'eval_samples_per_second': 486.802, 'eval_steps_per_second': 15.578, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be0f0bb4-e8e9-48b1-9e1e-2e74c8f51fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d4be95315f4542a17e1205068cac1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-3.9271808 , -3.1209285 , -4.3894625 , ..., -3.6100576 ,\n",
      "        -4.401446  , -4.186394  ],\n",
      "       [-2.9825072 , -3.3565352 , -5.2395205 , ...,  1.6936542 ,\n",
      "        -3.4803228 , -3.8520677 ],\n",
      "       [ 0.23840736, -3.3388488 , -2.9050484 , ..., -1.7254094 ,\n",
      "        -3.3295286 , -1.2810366 ],\n",
      "       ...,\n",
      "       [-3.8575442 , -2.9342434 , -4.6032095 , ..., -3.4704201 ,\n",
      "        -4.4367795 , -4.2635236 ],\n",
      "       [-4.0914125 ,  2.8136544 , -6.530663  , ..., -3.807361  ,\n",
      "        -4.734856  , -5.6108866 ],\n",
      "       [-3.5844002 , -2.249797  , -2.9839425 , ..., -2.3815846 ,\n",
      "         1.2088852 , -4.242043  ]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32), metrics={'test_loss': 0.0621742382645607, 'test_accuracy_thresh': 0.9867501854896545, 'test_f1_micro': 0.8902501276161306, 'test_f1_macro': 0.5756649900255171, 'test_eval_f1': 0.8902501276161306, 'test_runtime': 7.2927, 'test_samples_per_second': 513.799, 'test_steps_per_second': 16.18})\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "labels, id2label, label2id = get_label_metadata(test_dataset)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset )\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5fd1085-059a-4389-9873-d5f5ff454551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Another_Study\n",
      "Precision: 0.9612903225806452\n",
      "Recall: 0.7487437185929648\n",
      "Label: Business_Administrative\n",
      "Precision: 0.9629629629629629\n",
      "Recall: 0.952020202020202\n",
      "Label: Covid19\n",
      "Precision: 0.9891891891891892\n",
      "Recall: 1.0\n",
      "Label: Endpoint_Met\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Label: Ethical_Reason\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Label: Insufficient_Data\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Label: Insufficient_Enrollment\n",
      "Precision: 0.9792256846081209\n",
      "Recall: 0.9646511627906976\n",
      "Label: Interim_Analysis\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Label: Invalid_Reason\n",
      "Precision: 0.885593220338983\n",
      "Recall: 0.836\n",
      "Label: Logistics_Resources\n",
      "Precision: 0.9521276595744681\n",
      "Recall: 0.5946843853820598\n",
      "Label: Negative\n",
      "Precision: 0.9603399433427762\n",
      "Recall: 0.9211956521739131\n",
      "Label: No_Context\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Label: Regulatory\n",
      "Precision: 0.8842105263157894\n",
      "Recall: 0.75\n",
      "Label: Safety_Sideeffects\n",
      "Precision: 0.9633507853403142\n",
      "Recall: 0.8720379146919431\n",
      "Label: Study_Design\n",
      "Precision: 0.9310344827586207\n",
      "Recall: 0.6990291262135923\n",
      "Label: Study_Staff_Moved\n",
      "Precision: 0.9935483870967742\n",
      "Recall: 0.9333333333333333\n",
      "Label: Success\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "\n",
    "# Compute precision and recall\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Print precision and recall per class\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6523a57f-7a14-418f-a42f-a55e2a524160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9613    0.7487    0.8418       199\n",
      "Business_Administrative     0.9630    0.9520    0.9575       792\n",
      "                Covid19     0.9892    1.0000    0.9946       183\n",
      "           Endpoint_Met     0.0000    0.0000    0.0000        51\n",
      "         Ethical_Reason     0.0000    0.0000    0.0000        17\n",
      "      Insufficient_Data     0.0000    0.0000    0.0000        39\n",
      "Insufficient_Enrollment     0.9792    0.9647    0.9719      1075\n",
      "       Interim_Analysis     0.0000    0.0000    0.0000        28\n",
      "         Invalid_Reason     0.8856    0.8360    0.8601       250\n",
      "    Logistics_Resources     0.9521    0.5947    0.7321       301\n",
      "               Negative     0.9603    0.9212    0.9404       368\n",
      "             No_Context     0.0000    0.0000    0.0000        83\n",
      "             Regulatory     0.8842    0.7500    0.8116       112\n",
      "     Safety_Sideeffects     0.9634    0.8720    0.9154       211\n",
      "           Study_Design     0.9310    0.6990    0.7985       309\n",
      "      Study_Staff_Moved     0.9935    0.9333    0.9625       165\n",
      "                Success     0.0000    0.0000    0.0000        21\n",
      "\n",
      "              micro avg     0.9604    0.8297    0.8903      4204\n",
      "              macro avg     0.6155    0.5454    0.5757      4204\n",
      "           weighted avg     0.9046    0.8297    0.8620      4204\n",
      "            samples avg     0.9183    0.8758    0.8891      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9043a-f2e5-4073-aabc-060170da4cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29a1bc93-e604-4337-9cf2-b7e488cd0749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './checkpoint-1908'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 28\u001b[0m\n\u001b[1;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     13\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./save_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m         evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m model_saved\u001b[38;5;241m=\u001b[39minstantiate_classifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomenicrosati/ClinicalTrialBioBert\u001b[39m\u001b[38;5;124m'\u001b[39m,labels, id2label, label2id)\n\u001b[0;32m---> 28\u001b[0m model_saved\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./checkpoint-1908\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultilabelTrainer(\n\u001b[1;32m     30\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_saved,\n\u001b[1;32m     31\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m         compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     37\u001b[0m     ) \n",
      "File \u001b[0;32m~/clinical_bio_bert/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/clinical_bio_bert/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/clinical_bio_bert/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './checkpoint-1908'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./checkpoint-1908', do_lower_case=True)\n",
    "dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "#print(tokenized_dataset)\n",
    "train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, False)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir='./save_strategy',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=7,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='no'\n",
    "    )\n",
    "model_saved=instantiate_classifier('domenicrosati/ClinicalTrialBioBert',labels, id2label, label2id)\n",
    "model_saved.load_state_dict()\n",
    "trainer = MultilabelTrainer(\n",
    "        model=model_saved,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c61c4624-8300-4bf9-bb0f-c9e19bf1a1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_f1': 0.06200676437429538,\n",
       " 'eval_loss': 0.6827786564826965,\n",
       " 'eval_accuracy_thresh': 0.1115294098854065,\n",
       " 'eval_f1_micro': 0.06200676437429538,\n",
       " 'eval_f1_macro': 0.029591224151904724,\n",
       " 'eval_runtime': 0.7564,\n",
       " 'eval_samples_per_second': 495.746,\n",
       " 'eval_steps_per_second': 15.864}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7e5337-df73-4165-885f-b4c90d8ecc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel,PeftConfig\n",
    "def instantiate_classifier_finetuned(model_name,labels, id2label, label2id):\n",
    "    \"\"\"\n",
    "    We're instantiating a BERT model, and then replacing the classification layer with a custom one for our task.\n",
    "    \n",
    "    Args:\n",
    "      labels: a list of all the labels in the dataset\n",
    "      id2label: a dictionary mapping from label ids to label names\n",
    "      label2id: a dictionary mapping labels to integers\n",
    "    \n",
    "    Returns:\n",
    "      A model with a classifier that has 3 layers.\n",
    "    \"\"\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       'domenicrosati/ClinicalTrialBioBert',\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model,model_name,is_trainable=True)\n",
    "    merged_model=model.merge_and_unload()\n",
    "    for param in merged_model.parameters():\n",
    "         param.requires_grad = True\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(labels))\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def training(\n",
    "    epochs= 20 ,\n",
    "    output_model_name= 'stop_reasons',\n",
    "    subset_data: bool = False,\n",
    "    push_to_hub: bool = False,\n",
    "    personal_token: Optional[str] = None,\n",
    "    model_name='domenicrosati/ClinicalTrialBioBert'\n",
    "):\n",
    "    \"\"\"\n",
    "    Main logic of the fine-tuning process: this function loads the dataset, tokenizes it,\n",
    "    splits it into train and validation sets, loads the model, trains it, and saves it\n",
    "    \n",
    "    Args:\n",
    "      epochs (int): number of epochs to train for\n",
    "      output_model_name (str): filename and path to the directory where the model will be saved.\n",
    "      subset_data (bool): flag to indicate whether to use a subset of the data for testing purposes\n",
    "      push_to_hub (bool): flag to indicate whether to push the model to the hub\n",
    "      personal_token (str | None): your personal Hugging Face Hub token\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='train').train_test_split(test_size=0.1, seed=42)\n",
    "    #print(dataset)\n",
    "    global labels\n",
    "    labels, id2label, label2id = get_label_metadata(dataset)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('domenicrosati/ClinicalTrialBioBert', do_lower_case=True)\n",
    "    dataset_cols = [col for col in dataset[\"train\"].column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "    #print(tokenized_dataset)\n",
    "    train_dataset, test_dataset = prepare_splits_for_training(tokenized_dataset, subset_data)\n",
    "    #print(train_dataset)\n",
    "    logging.info(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_model_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        weight_decay=0.01,\n",
    "        data_seed=42,\n",
    "        num_train_epochs=epochs,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        save_strategy='no'\n",
    "    )\n",
    "    trainer = MultilabelTrainer(\n",
    "        model= instantiate_classifier_finetuned(model_name,labels, id2label, label2id),\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    print(predictions)\n",
    "    # trainer.save_model(output_model_name)\n",
    "    # if push_to_hub:\n",
    "    #     trainer.push_to_hub()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5b13e69-e676-4a07-a3fc-ab17793df159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset length: 3372\n",
      "INFO:root:Test dataset length: 375\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at domenicrosati/ClinicalTrialBioBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2120/2120 06:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.210394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155732</td>\n",
       "      <td>0.530478</td>\n",
       "      <td>0.952471</td>\n",
       "      <td>0.530478</td>\n",
       "      <td>0.152572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.130636</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.958902</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.202407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114937</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.963608</td>\n",
       "      <td>0.676301</td>\n",
       "      <td>0.332821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.104436</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.967216</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.420913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.467878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>0.969412</td>\n",
       "      <td>0.761780</td>\n",
       "      <td>0.493684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.095487</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.504375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.094918</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.970039</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.524676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>0.774112</td>\n",
       "      <td>0.970039</td>\n",
       "      <td>0.774112</td>\n",
       "      <td>0.511452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.968314</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.503317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098878</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.534353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.968627</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.534677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.101749</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.542897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.100096</td>\n",
       "      <td>0.770389</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.770389</td>\n",
       "      <td>0.551078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.105217</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.543291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>0.762861</td>\n",
       "      <td>0.538474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.102330</td>\n",
       "      <td>0.765370</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.765370</td>\n",
       "      <td>0.540003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.103986</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.967373</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.542820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.104307</td>\n",
       "      <td>0.769614</td>\n",
       "      <td>0.967843</td>\n",
       "      <td>0.769614</td>\n",
       "      <td>0.545873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_f1': 0.7696139476961394, 'eval_loss': 0.10430705547332764, 'eval_accuracy_thresh': 0.9678431153297424, 'eval_f1_micro': 0.7696139476961394, 'eval_f1_macro': 0.5458725394836774, 'eval_runtime': 0.8003, 'eval_samples_per_second': 468.555, 'eval_steps_per_second': 14.994, 'epoch': 20.0}\n",
      "PredictionOutput(predictions=array([[-6.327882 , -5.5061526, -6.6775985, ..., -2.8965   , -6.376354 ,\n",
      "        -7.5506186],\n",
      "       [-6.344967 , -6.221231 , -6.6962476, ..., -4.3206105, -6.6697307,\n",
      "        -7.7399435],\n",
      "       [-6.259497 , -5.7451634, -6.751837 , ..., -4.6739883, -6.5754023,\n",
      "        -7.640315 ],\n",
      "       ...,\n",
      "       [ 3.2270386, -3.6547203, -5.0737753, ..., -5.015713 , -5.2820845,\n",
      "        -5.5807095],\n",
      "       [-4.67397  , -4.587115 , -6.628884 , ...,  3.382313 , -5.016668 ,\n",
      "        -6.397219 ],\n",
      "       [-4.1944165, -1.1102599, -5.3798323, ..., -3.7680554, -5.387648 ,\n",
      "        -5.6805696]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), metrics={'test_loss': 0.10430705547332764, 'test_accuracy_thresh': 0.9678431153297424, 'test_f1_micro': 0.7696139476961394, 'test_f1_macro': 0.5458725394836774, 'test_eval_f1': 0.7696139476961394, 'test_runtime': 0.8029, 'test_samples_per_second': 467.057, 'test_steps_per_second': 14.946})\n"
     ]
    }
   ],
   "source": [
    "trainer_new=training(model_name='checkpoint-205835')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4da71dca-68c3-4b2e-bfe5-a55c01de120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9744    0.9548    0.9645       199\n",
      "Business_Administrative     0.9712    0.9811    0.9761       792\n",
      "                Covid19     0.9946    1.0000    0.9973       183\n",
      "           Endpoint_Met     0.9474    0.7059    0.8090        51\n",
      "         Ethical_Reason     1.0000    0.1176    0.2105        17\n",
      "      Insufficient_Data     1.0000    0.1795    0.3043        39\n",
      "Insufficient_Enrollment     0.9861    0.9898    0.9879      1075\n",
      "       Interim_Analysis     1.0000    0.8214    0.9020        28\n",
      "         Invalid_Reason     0.9790    0.9320    0.9549       250\n",
      "    Logistics_Resources     0.9148    0.9269    0.9208       301\n",
      "               Negative     0.9782    0.9755    0.9769       368\n",
      "             No_Context     1.0000    0.7952    0.8859        83\n",
      "             Regulatory     0.9717    0.9196    0.9450       112\n",
      "     Safety_Sideeffects     0.9857    0.9810    0.9834       211\n",
      "           Study_Design     0.9394    0.9029    0.9208       309\n",
      "      Study_Staff_Moved     1.0000    0.9636    0.9815       165\n",
      "                Success     1.0000    0.0952    0.1739        21\n",
      "\n",
      "              micro avg     0.9733    0.9441    0.9585      4204\n",
      "              macro avg     0.9790    0.7790    0.8173      4204\n",
      "           weighted avg     0.9738    0.9441    0.9524      4204\n",
      "            samples avg     0.9654    0.9564    0.9577      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer_new.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aa34ebc-078d-4ea5-8f5f-191630cdb280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          Another_Study     0.9613    0.8744    0.9158       199\n",
      "Business_Administrative     0.9712    0.8939    0.9310       792\n",
      "                Covid19     1.0000    1.0000    1.0000       183\n",
      "           Endpoint_Met     0.0000    0.0000    0.0000        51\n",
      "         Ethical_Reason     0.0000    0.0000    0.0000        17\n",
      "      Insufficient_Data     0.0000    0.0000    0.0000        39\n",
      "Insufficient_Enrollment     0.9675    0.9684    0.9679      1075\n",
      "       Interim_Analysis     0.0000    0.0000    0.0000        28\n",
      "         Invalid_Reason     0.9174    0.8880    0.9024       250\n",
      "    Logistics_Resources     0.9196    0.6080    0.7320       301\n",
      "               Negative     0.9535    0.8913    0.9213       368\n",
      "             No_Context     0.0000    0.0000    0.0000        83\n",
      "             Regulatory     0.0000    0.0000    0.0000       112\n",
      "     Safety_Sideeffects     0.9558    0.8199    0.8827       211\n",
      "           Study_Design     0.9254    0.6019    0.7294       309\n",
      "      Study_Staff_Moved     0.9630    0.9455    0.9541       165\n",
      "                Success     0.0000    0.0000    0.0000        21\n",
      "\n",
      "              micro avg     0.9588    0.7978    0.8709      4204\n",
      "              macro avg     0.5609    0.4995    0.5257      4204\n",
      "           weighted avg     0.8770    0.7978    0.8319      4204\n",
      "            samples avg     0.8890    0.8455    0.8591      4204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ila/clinical_bio_bert/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_dataset = load_dataset(\"opentargets/clinical_trial_reason_to_stop\", split='all')\n",
    "\n",
    "# Tokenize test dataset\n",
    "\n",
    "dataset_cols = [col for col in test_dataset.column_names if col not in [\"text\", \"input_ids\", \"attention_mask\", \"labels\"]]\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True, remove_columns=dataset_cols)\n",
    "predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "true_labels = tokenized_test_dataset[\"labels\"]\n",
    "# Get predictions\n",
    "sigmoid_threshold = 0.3\n",
    "\n",
    "# Convert probabilities to binary predictions using threshold\n",
    "predicted_labels = (predictions > sigmoid_threshold).astype(int)\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels, digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical_bio_bert",
   "language": "python",
   "name": "clinical_bio_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
